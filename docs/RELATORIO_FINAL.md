# RelatÃ³rio Final - Projeto de Machine Learning

**Aluno(a):** 
- Alison Jose Serafim - 01704127
- Jose Adilmo Antonio Guimaraes - 01686937
- Elivelton Gomes - 01676905
- Patrik Moreira - 01690377
- JosÃ© Victor Alves - 01688969

**Disciplina:** IntroduÃ§Ã£o Ã  Machine Learning - 2025.2
**Professor:** Professor Durval
**Data:** 30/11/2025
**RepositÃ³rio:** [text](https://github.com/Alisonjs0/uninassau-atividade-alunos-ml-regressao)

---

## ğŸ“‹ SumÃ¡rio Executivo

Este projeto teve como objetivo prever o tempo de entrega (delivery_time_hours) de pedidos logÃ­sticos utilizando tÃ©cnicas de Machine Learning. O dataset contÃ©m informaÃ§Ãµes de 2.510 entregas com caracterÃ­sticas relacionadas ao clima, trÃ¡fego, veÃ­culo e motorista. ApÃ³s o prÃ©-processamento, engenharia de atributos e comparaÃ§Ã£o de modelos, a RegressÃ£o Linear apresentou uma excelente performance, alcanÃ§ando um RMSE de 0.25 e um RÂ² de 0.93 no conjunto de teste, indicando uma alta capacidade de generalizaÃ§Ã£o e precisÃ£o nas estimativas de tempo

## ğŸ¯ 1. IntroduÃ§Ã£o

### 1.1 ContextualizaÃ§Ã£o do Problema

Empresas de logÃ­stica enfrentam o desafio constante de estimar prazos de entrega com precisÃ£o. Atrasos impactam a satisfaÃ§Ã£o do cliente, enquanto estimativas muito longas podem desencorajar vendas. A utilizaÃ§Ã£o de dados histÃ³ricos para prever o tempo exato em horas permite otimizar rotas, gerenciar expectativas e alocar recursos de forma mais eficiente.

- **Objetivo Geral:** 
Desenvolver um modelo preditivo para estimar o tempo de entrega em horas (delivery_time_hours).

- **Objetivos EspecÃ­ficos:**
  1. Identificar fatores crÃ­ticos que aumentam o tempo de entrega (ex: clima, trÃ¢nsito).
  2. Tratar dados faltantes e inconsistÃªncias no dataset bruto.
  3. Criar novas features (Feature Engineering) para enriquecer o modelo.
  4. Obter um modelo com RÂ² superior a 0.90

### 1.3 Dataset

- **Nome:** Delivery Time Dataset (delivery_time.csv)
- **Fonte:** RegressÃ£o Supervised.
- **Tamanho:** 2.510 registros, 17 colunas originais.
- **VariÃ¡vel Alvo:** delivery_time_hours (NumÃ©rica/ContÃ­nua).
- **Tipo de Problema:** RegressÃ£o Supervised.

---

## ğŸ“Š 2. AnÃ¡lise ExploratÃ³ria de Dados (EDA)

### 2.1 VisÃ£o Geral dos Dados

| MÃ©trica | Valor |
|---------|-------|
| Total de Registros | 2510 |
| Total de Features | 17 |
| Features NumÃ©ricas | 7 |
| Features CategÃ³ricas | 10 |
| Valores Faltantes (%) | 12.19% |

### 2.2 Principais Descobertas

#### 2.2.1 AnÃ¡lise da VariÃ¡vel Alvo

> Descreva a distribuiÃ§Ã£o de `delivery_time_hours`.

- **MÃ©dia:** 19.14 Horas
- **Mediana:**  18.49
- **Desvio PadrÃ£o:** 9.4
- **Faixa:** 0.5 - 51.55 Horas
- **DistribuiÃ§Ã£o:** Aproximadamente normal, mas com uma leve assimetria Ã  direita

**![alt text](../src/assets/Distribuicao.png)**

#### 2.2.2 CorrelaÃ§Ãµes

> Identificou-se, atravÃ©s dos coeficientes da RegressÃ£o Linear (Etapa 3), que as condiÃ§Ãµes adversas tÃªm alto impacto:

   weather_tempestade: Aumenta significativamente o tempo.
   traffic_condition_congestionado: Forte impacto positivo no tempo.
   time_of_day_tarde: HorÃ¡rio com tendÃªncia de aumento no tempo.

**![alt text](../src/assets/Matriz_correlaÃ§Ã£o.png)**

#### 2.2.3 Valores Faltantes

   > Como os valores faltantes estÃ£o distribuÃ­dos?

   |Os valores faltantes estavam distribuÃ­dos principalmente em:
   Feature                   | Missing (%) | EstratÃ©gia de Tratamento
   wellbeing_score           | 12.19%      | ImputaÃ§Ã£o pela mediana
   traffic_condition         | 10.16%      | ImputaÃ§Ã£o pela moda (Mais frequente)
   package_weight_kg         | 7.77%       | ImputaÃ§Ã£o pela mediana
   driver_experience_years   | 6.57%       | ImputaÃ§Ã£o pela mediana

#### 2.2.4 Outliers

> Quais outliers foram identificados e como foram tratados?

   ### IdentificaÃ§Ã£o: 
   MÃ©todo IQR (Q1 - 1.5IQR, Q3 + 1.5IQR).
   ### Tratamento: 
   Capping (substituiÃ§Ã£o pelos limites inferior e superior calculados) aplicado em todas as variÃ¡veis numÃ©ricas para reduzir ruÃ­do sem perder dados.

## ğŸ”§ 3. PrÃ©-processamento e Feature Engineering

### 3.1 Tratamento de Dados

#### 3.1.1 Valores Faltantes

   ### VariÃ¡veis numÃ©ricas: 
   SimpleImputer com estratÃ©gia 'median'.
   ### VariÃ¡veis categÃ³ricas:
   SimpleImputer com estratÃ©gia 'most_frequent'.
   ### Justificativa:
   A mediana Ã© mais robusta a outliers para dados numÃ©ricos, e a moda preserva a categoria mais provÃ¡vel para dados categÃ³ricos.

#### 3.1.2 Encoding de CategÃ³ricas

   ### One-Hot Encoding (pd.get_dummies): 
   Aplicado em delivery_type, vehicle_type, traffic_condition, weather, time_of_day, day_of_week, is_priority, package_fragile, delivery_zone.
   ### Justificativa: 
   As variÃ¡veis nÃ£o possuem ordem ordinal intrÃ­nseca (nominais), tornando o One-Hot ideal. drop_first=True foi usado para evitar multicolinearidade.


#### 3.1.3 NormalizaÃ§Ã£o/PadronizaÃ§Ã£o
   ### MÃ©todo: 
   StandardScaler.
   ### Aplicado a: 
   Todas as features numÃ©ricas (distance_km, package_weight_kg, etc.).
   ### Justificativa: 
   NecessÃ¡rio para colocar todas as variÃ¡veis na mesma escala (mÃ©dia 0, desvio padrÃ£o 1), essencial para modelos lineares e benÃ©fico para a convergÃªncia de outros algoritmos.

### 3.2 Feature Engineering

> Novas features criadas na Etapa 2:

   Nova Feature                  FÃ³rmula/DescriÃ§Ã£o                                        Justificativa

   wellbeing_score   customer_rating + driver_exp - delivery_time             Captura eficiÃªncia/satisfaÃ§Ã£o composta.
   delivery_speed_kmh   distance_km / (delivery_time_hours + epsilon)           Cria uma mÃ©trica de velocidade mÃ©dia.

   ### Nota: 
   Observou-se que essas features utilizam a variÃ¡vel alvo (delivery_time_hours) em sua construÃ§Ã£o, o que elevou artificialmente a performance na Etapa 3 (RÂ² ~0.94), mas o modelo final na Etapa 4 (RÂ² 0.70) sugere uma generalizaÃ§Ã£o mais realista ou ajuste nos dados de treino.

## ğŸ¤– 4. Modelagem

### 4.1 DivisÃ£o dos Dados

   DivisÃ£o inicial: 80% Treino / 20% Teste (usado no RandomizedSearchCV).
   Random State: 42 (para reprodutibilidade).

### 4.2 Modelos Testados

> Liste todos os modelos treinados.

#	Modelo	         HiperparÃ¢metros	   RMSE (Val)	   MAE (Val)	RÂ² (Val)
1	RegressÃ£o Linear	   padrÃ£o	            0,254	      0,175	      0,936
2	Floresta AleatÃ³ria	n_estimators=237,    5,599	      1,705	      0,700
                        max_depth=14, 
                        min_samples_split=11,  
                        min_samples_leaf=1, 
                        max_features='sqrt', 
                        bootstrap=False

**Melhor Modelo:**  RegressÃ£o Linear

### 4.3 OtimizaÃ§Ã£o de HiperparÃ¢metros

> ### Melhor modelo 
   (Random Forest).
   ### MÃ©todo: 
   RandomizedSearchCV com 5-fold cross-validation.
   ### HiperparÃ¢metros Testados:

   n_estimators: 50 a 500
   max_depth: 3 a 3
   min_samples_split: 2 a 20
   max_features: ['sqrt', 'log2']

   ### Melhores HiperparÃ¢metros Encontrados:
   {
   'n_estimators': 237,
   'min_samples_split': 11,
   'min_samples_leaf': 1,
   'max_features': 'sqrt',
   'max_depth': 14,
   'bootstrap': False
   }

## ğŸ“ˆ 5. Resultados

### 5.1 Performance no Conjunto de Teste

> Resultados finais do modelo Random Forest otimizado (Etapa 4):

MÃ©trica           Valor                      InterpretaÃ§Ã£o              
RMSE              5.5992           O erro mÃ©dio das previsÃµes Ã© de aprox. 5.6 horas.
MAE               1.7051           Erro absoluto mÃ©dio de 1.7 horas.
RÂ²                0.7000            O modelo explica 70% da variabilidade dos dados.
**![alt text](../src/assets/PreditoXreal.png)**

### 5.2 AnÃ¡lise de ResÃ­duos

> Verifique se os resÃ­duos sÃ£o bem comportados.

- **DistribuiÃ§Ã£o:** [ex: Aproximadamente normal, centrada em 0]
- **Homocedasticidade:** [ex: VariÃ¢ncia constante ao longo das prediÃ§Ãµes]
- **PadrÃµes:** [ex: Nenhum padrÃ£o claro detectado]

**![alt text](../src/assets/ResiduosPredicoes.png)]**
**![alt text](../src/assets/Histograma_distribuicao_de_residuos.png)]**

### 5.3 Feature Importance

> Quais features foram mais importantes para o modelo?

   ## Baseado nos coeficientes lineares e na lÃ³gica do negÃ³cio (Etapa 3), as variÃ¡veis mais impactantes incluem:
   weather_tempestade: Forte aumento no tempo de entrega.
   traffic_condition_congestionado: Aumento significativo devido ao trÃ¢nsito.
   day_of_week: Dias como Domingo apresentaram coeficientes relevantes.

**[![alt text](../src/assets/Feature_Importance.png)]**

---

## ğŸ’¡ 6. ConclusÃµes e Insights

## 6.1 Principais Descobertas

   OtimizaÃ§Ã£o Funciona: O processo de RandomizedSearch melhorou drasticamente o RÂ² de ~0.05 para 0.70 no Random Forest.
   Fatores Externos: CondiÃ§Ãµes climÃ¡ticas severas (Tempestade) e trÃ¡fego sÃ£o os maiores ofensores para atrasos.
   Data Leakage: A criaÃ§Ã£o de features como delivery_speed_kmh usando a variÃ¡vel alvo deve ser revista em produÃ§Ã£o, pois explica a performance anormalmente alta na RegressÃ£o Linear (RÂ² 0.94) comparada ao Random Forest realista (RÂ² 0.70).

### 6.2 LimitaÃ§Ãµes do Modelo

   O modelo final ainda apresenta um RMSE de ~5.6 horas, o que pode ser alto para entregas expressas.
   DependÃªncia de features criadas a partir do target na fase de EDA pode ter enviesado a anÃ¡lise preliminar.
   Dataset com valores imputados (cerca de 12% em algumas colunas) pode introduzir ruÃ­do.

### 6.3 RecomendaÃ§Ãµes

   Remover features derivadas do target (delivery_speed_kmh) para evitar vazamento de dados em produÃ§Ã£o.
   Coletar dados de trÃ¢nsito em tempo real (API) em vez de usar categorias estÃ¡ticas.
   Focar em melhorar a logÃ­stica nos dias de chuva forte e trÃ¢nsito congestionado, talvez alterando o tipo de veÃ­culo.

### 6.4 Trabalhos Futuros

   Testar algoritmos de Boosting como XGBoost ou LightGBM.
   Implementar validaÃ§Ã£o temporal (se houver data no dataset) para simular o cenÃ¡rio real.
   Realizar uma anÃ¡lise SHAP para explicar a prediÃ§Ã£o de cada entrega individualmente.

ğŸ“š 7. ReferÃªncias

DocumentaÃ§Ã£o Scikit-learn: https://scikit-learn.org/
Pandas User Guide: https://pandas.pydata.org/docs/
Material de aula - Professor Durval.

## ğŸ“ 8. Anexos

### Anexo A: Estrutura do RepositÃ³rio
```
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/students_performance.csv
â”‚   â””â”€â”€ processed/dataset_clean.csv
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_EDA.ipynb
â”‚   â”œâ”€â”€ 02_Preprocessamento_Baseline.ipynb
â”‚   â”œâ”€â”€ 03_Modelos_Avancados.ipynb
â”‚   â””â”€â”€ 04_Otimizacao_Final.ipynb
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ RELATORIO_FINAL.md
â””â”€â”€ README.md
```

### Anexo B: Ambiente de Desenvolvimento
```
Python: 3.10.x
Bibliotecas principais:
- pandas==2.0.3
- scikit-learn==1.3.0
- xgboost==1.7.6
- matplotlib==3.7.2
- seaborn==0.12.2
```

---

**Data de ConclusÃ£o:** [01/11/2025]
**Ãšltima atualizaÃ§Ã£o:** [30/11/2025]
